{
  "observation_shape": [
    17
  ],
  "action_size": 6,
  "config": {
    "type": "decision_transformer",
    "params": {
      "batch_size": 64,
      "gamma": 0.99,
      "observation_scaler": {
        "type": "standard",
        "params": {
          "mean": [
            -0.06845804438781738,
            0.01641461775688827,
            -0.18355838536119462,
            -0.27624860682296754,
            -0.34113872618675234,
            -0.0933961015996933,
            -0.2132119082584381,
            -0.08774357607841492,
            5.173194129859924,
            -0.042751853255033494,
            -0.036108797529459,
            0.14053658367276192,
            0.06049891131395101,
            0.09550849614304305,
            0.06739012960809469,
            0.00562735379755497,
            0.01338256095315516
          ],
          "std": [
            0.07475441136308308,
            0.30250719660452735,
            0.3021580964433145,
            0.3442407787586174,
            0.17633868582496792,
            0.5072853417004966,
            0.25675922700056203,
            0.32956260124858067,
            1.2578190100012563,
            0.7602306888844942,
            1.9805892925503585,
            6.568254194917617,
            7.467826330639622,
            4.4744745580840855,
            10.569660235277562,
            5.673224899433819,
            7.5004142378307135
          ],
          "eps": 0.001
        }
      },
      "action_scaler": {
        "type": "none",
        "params": {}
      },
      "reward_scaler": {
        "type": "multiply",
        "params": {
          "multiplier": 0.001
        }
      },
      "context_size": 20,
      "max_timestep": 1000,
      "learning_rate": 0.0001,
      "encoder_factory": {
        "type": "vector",
        "params": {
          "hidden_units": [
            128
          ],
          "activation": "relu",
          "use_batch_norm": false,
          "dropout_rate": null,
          "exclude_last_activation": true
        }
      },
      "optim_factory": {
        "type": "adam_w",
        "params": {
          "betas": [
            0.9,
            0.999
          ],
          "eps": 1e-08,
          "weight_decay": 0.0001,
          "amsgrad": false
        }
      },
      "num_heads": 1,
      "num_layers": 3,
      "attn_dropout": 0.1,
      "resid_dropout": 0.1,
      "embed_dropout": 0.1,
      "activation_type": "relu",
      "position_encoding_type": "simple",
      "warmup_steps": 10000,
      "clip_grad_norm": 0.25,
      "compile": false
    }
  }
}